# GPP Columnar File Format

A from-scratch implementation of a **columnar analytical file format** (similar to Parquet/ORC) written in Python.

---

## ðŸš€ Overview

This project:

- Defines a custom **binary columnar file format** (`.gppcol`)
- Includes a **writer** (CSV â†’ GPP) & **reader** (GPP â†’ CSV)
- Supports **column pruning** for fast selective reads
- Uses **zlib compression per column**
- Includes **CLI tools + tests + benchmarks**
- Demonstrates performance improvement for analytical workloads

---

## âœ¨ Features

- Columnar storage â€” each column stored independently & compressed
- File header stores:
  - magic number, version, endianness
  - row count, column count
  - per-column metadata: name, type, offset, compressed/uncompressed sizes
- Supported types:
  - `int32`, `float64`, `string` (UTF-8 w/ offsets), `bool`
- Full-file read + **read only selected columns**
- Round-trip CSV â†’ GPP â†’ CSV **bitwise identical**
- Benchmark example: single column read is **faster** than CSV

---

## ðŸ“‚ Project Structure

```
columnar-file-format/
â”œâ”€ src/
â”‚ â”œâ”€ __init__.py
â”‚ â”œâ”€ gpp_writer.py        # CSV -> GPP
â”‚ â”œâ”€ gpp_reader.py        # GPP -> CSV/Python reader
â”‚ â””â”€ cli.py               # CLI & interactive menu
â”œâ”€ data/
â”‚ â”œâ”€ test.csv
â”‚ â””â”€ benchmark results generated here
â”œâ”€ tests/
â”‚ â”œâ”€ test_roundtrip.py
â”‚ â””â”€ benchmark_single_column.py
â”œâ”€ SPEC.md
â”œâ”€ README.md
â””â”€ main.py                # Entry point (recommended)
```

---

## âš¡ Quick Start

```bash
git clone <repo-url>
cd columnar-file-format
python main.py
```

You will see:

```
========================================
   GPP Columnar File Format CLI
========================================
1) CSV -> GPP (.gppcol)
2) GPP (.gppcol) -> CSV
3) Show file schema
4) Read specific columns
5) Round-trip test
6) Run benchmark
0) Exit
```

---

## ðŸ§ª CLI Usage

### 1) Convert CSV â†’ GPP  
Converts CSV into compressed columnar `.gppcol`.

### 2) Convert GPP â†’ CSV  
Restores CSV from `.gppcol` fully.

### 3) View Schema  
Shows metadata, row count, column names & types.

### 4) Selective Column Read  
Reads only chosen columns (fast due to column pruning).

Example:

```
Enter columns: id,name
```

### 5) Round-Trip Test  
Verifies CSV â†’ GPP â†’ CSV integrity.

Output:

```
âœ” Round-trip successful (files match)
```

### 6) Benchmark

```
CSV: 0.42s
GPP: 0.12s
Speedup: ~3.5x
```

---

## ðŸ§ª Running Tests / Using Modules Manually

You can run tests or use writer/reader modules independently for custom workflows.

```bash
# Round-trip integrity test
python tests/test_roundtrip.py data/test.csv
# Benchmark
python tests/benchmark_single_column.py
```

---

## ðŸ”¥ Future Enhancements

- ðŸŸ¡ Null value support
- ðŸŸ¡ More data types (date, decimal)
- ðŸŸ¡ Dictionary encoding for repeated strings
- ðŸŸ¡ Chunked row-groups â†’ predicate pushdown
- ðŸŸ¡ Optional compression: Snappy/LZ4/ZSTD

---

## ðŸ™Œ Final Words

Thank you for checking out this project!  
Clone â†’ Run â†’ Experiment â†’ Learn how real data formats work.

> Note: For easier understanding and demonstrations, the sample dataset included here is intentionally small.  
> However, this system is fully capable of handling large datasets efficiently â€” as long as the columns follow the supported data types.

